{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a2307f04-96ac-4a77-b10a-061c6b4f5728",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4f73d019-1f63-4211-92ec-9f8a2d180acb",
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "33f2ee89-4aa6-4fb4-b00d-49bc2bd2c78b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "944587f9-d8eb-4c98-87d8-ef764ef1979f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2bb48316-ec36-4e31-b207-16a33a0a29b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('WineQT.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2d57751e-e220-4d4b-bea2-28b4bfd25be2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "      <th>Id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.700</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.99780</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.880</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.098</td>\n",
       "      <td>25.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.99680</td>\n",
       "      <td>3.20</td>\n",
       "      <td>0.68</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.760</td>\n",
       "      <td>0.04</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.092</td>\n",
       "      <td>15.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.99700</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.65</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.2</td>\n",
       "      <td>0.280</td>\n",
       "      <td>0.56</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.075</td>\n",
       "      <td>17.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.99800</td>\n",
       "      <td>3.16</td>\n",
       "      <td>0.58</td>\n",
       "      <td>9.8</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.700</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.99780</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1138</th>\n",
       "      <td>6.3</td>\n",
       "      <td>0.510</td>\n",
       "      <td>0.13</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.076</td>\n",
       "      <td>29.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.99574</td>\n",
       "      <td>3.42</td>\n",
       "      <td>0.75</td>\n",
       "      <td>11.0</td>\n",
       "      <td>6</td>\n",
       "      <td>1592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1139</th>\n",
       "      <td>6.8</td>\n",
       "      <td>0.620</td>\n",
       "      <td>0.08</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.068</td>\n",
       "      <td>28.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>0.99651</td>\n",
       "      <td>3.42</td>\n",
       "      <td>0.82</td>\n",
       "      <td>9.5</td>\n",
       "      <td>6</td>\n",
       "      <td>1593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1140</th>\n",
       "      <td>6.2</td>\n",
       "      <td>0.600</td>\n",
       "      <td>0.08</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.090</td>\n",
       "      <td>32.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>0.99490</td>\n",
       "      <td>3.45</td>\n",
       "      <td>0.58</td>\n",
       "      <td>10.5</td>\n",
       "      <td>5</td>\n",
       "      <td>1594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1141</th>\n",
       "      <td>5.9</td>\n",
       "      <td>0.550</td>\n",
       "      <td>0.10</td>\n",
       "      <td>2.2</td>\n",
       "      <td>0.062</td>\n",
       "      <td>39.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>0.99512</td>\n",
       "      <td>3.52</td>\n",
       "      <td>0.76</td>\n",
       "      <td>11.2</td>\n",
       "      <td>6</td>\n",
       "      <td>1595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1142</th>\n",
       "      <td>5.9</td>\n",
       "      <td>0.645</td>\n",
       "      <td>0.12</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.075</td>\n",
       "      <td>32.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>0.99547</td>\n",
       "      <td>3.57</td>\n",
       "      <td>0.71</td>\n",
       "      <td>10.2</td>\n",
       "      <td>5</td>\n",
       "      <td>1597</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1143 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "0               7.4             0.700         0.00             1.9      0.076   \n",
       "1               7.8             0.880         0.00             2.6      0.098   \n",
       "2               7.8             0.760         0.04             2.3      0.092   \n",
       "3              11.2             0.280         0.56             1.9      0.075   \n",
       "4               7.4             0.700         0.00             1.9      0.076   \n",
       "...             ...               ...          ...             ...        ...   \n",
       "1138            6.3             0.510         0.13             2.3      0.076   \n",
       "1139            6.8             0.620         0.08             1.9      0.068   \n",
       "1140            6.2             0.600         0.08             2.0      0.090   \n",
       "1141            5.9             0.550         0.10             2.2      0.062   \n",
       "1142            5.9             0.645         0.12             2.0      0.075   \n",
       "\n",
       "      free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
       "0                    11.0                  34.0  0.99780  3.51       0.56   \n",
       "1                    25.0                  67.0  0.99680  3.20       0.68   \n",
       "2                    15.0                  54.0  0.99700  3.26       0.65   \n",
       "3                    17.0                  60.0  0.99800  3.16       0.58   \n",
       "4                    11.0                  34.0  0.99780  3.51       0.56   \n",
       "...                   ...                   ...      ...   ...        ...   \n",
       "1138                 29.0                  40.0  0.99574  3.42       0.75   \n",
       "1139                 28.0                  38.0  0.99651  3.42       0.82   \n",
       "1140                 32.0                  44.0  0.99490  3.45       0.58   \n",
       "1141                 39.0                  51.0  0.99512  3.52       0.76   \n",
       "1142                 32.0                  44.0  0.99547  3.57       0.71   \n",
       "\n",
       "      alcohol  quality    Id  \n",
       "0         9.4        5     0  \n",
       "1         9.8        5     1  \n",
       "2         9.8        5     2  \n",
       "3         9.8        6     3  \n",
       "4         9.4        5     4  \n",
       "...       ...      ...   ...  \n",
       "1138     11.0        6  1592  \n",
       "1139      9.5        6  1593  \n",
       "1140     10.5        5  1594  \n",
       "1141     11.2        6  1595  \n",
       "1142     10.2        5  1597  \n",
       "\n",
       "[1143 rows x 13 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3e1fdc49-cbfc-434e-9e42-722477d3abbb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1143, 13)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f825466a-0502-42a3-be6e-4f236f320c93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "356f3b8c-641a-4ea7-b83d-63403162ec39",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=['Id'], errors='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "620ef79c-7c5e-43dd-999c-936b78781a6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.700</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.99780</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.880</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.098</td>\n",
       "      <td>25.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.99680</td>\n",
       "      <td>3.20</td>\n",
       "      <td>0.68</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.760</td>\n",
       "      <td>0.04</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.092</td>\n",
       "      <td>15.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.99700</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.65</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.2</td>\n",
       "      <td>0.280</td>\n",
       "      <td>0.56</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.075</td>\n",
       "      <td>17.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.99800</td>\n",
       "      <td>3.16</td>\n",
       "      <td>0.58</td>\n",
       "      <td>9.8</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.700</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.99780</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1138</th>\n",
       "      <td>6.3</td>\n",
       "      <td>0.510</td>\n",
       "      <td>0.13</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.076</td>\n",
       "      <td>29.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.99574</td>\n",
       "      <td>3.42</td>\n",
       "      <td>0.75</td>\n",
       "      <td>11.0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1139</th>\n",
       "      <td>6.8</td>\n",
       "      <td>0.620</td>\n",
       "      <td>0.08</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.068</td>\n",
       "      <td>28.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>0.99651</td>\n",
       "      <td>3.42</td>\n",
       "      <td>0.82</td>\n",
       "      <td>9.5</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1140</th>\n",
       "      <td>6.2</td>\n",
       "      <td>0.600</td>\n",
       "      <td>0.08</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.090</td>\n",
       "      <td>32.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>0.99490</td>\n",
       "      <td>3.45</td>\n",
       "      <td>0.58</td>\n",
       "      <td>10.5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1141</th>\n",
       "      <td>5.9</td>\n",
       "      <td>0.550</td>\n",
       "      <td>0.10</td>\n",
       "      <td>2.2</td>\n",
       "      <td>0.062</td>\n",
       "      <td>39.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>0.99512</td>\n",
       "      <td>3.52</td>\n",
       "      <td>0.76</td>\n",
       "      <td>11.2</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1142</th>\n",
       "      <td>5.9</td>\n",
       "      <td>0.645</td>\n",
       "      <td>0.12</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.075</td>\n",
       "      <td>32.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>0.99547</td>\n",
       "      <td>3.57</td>\n",
       "      <td>0.71</td>\n",
       "      <td>10.2</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1143 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "0               7.4             0.700         0.00             1.9      0.076   \n",
       "1               7.8             0.880         0.00             2.6      0.098   \n",
       "2               7.8             0.760         0.04             2.3      0.092   \n",
       "3              11.2             0.280         0.56             1.9      0.075   \n",
       "4               7.4             0.700         0.00             1.9      0.076   \n",
       "...             ...               ...          ...             ...        ...   \n",
       "1138            6.3             0.510         0.13             2.3      0.076   \n",
       "1139            6.8             0.620         0.08             1.9      0.068   \n",
       "1140            6.2             0.600         0.08             2.0      0.090   \n",
       "1141            5.9             0.550         0.10             2.2      0.062   \n",
       "1142            5.9             0.645         0.12             2.0      0.075   \n",
       "\n",
       "      free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
       "0                    11.0                  34.0  0.99780  3.51       0.56   \n",
       "1                    25.0                  67.0  0.99680  3.20       0.68   \n",
       "2                    15.0                  54.0  0.99700  3.26       0.65   \n",
       "3                    17.0                  60.0  0.99800  3.16       0.58   \n",
       "4                    11.0                  34.0  0.99780  3.51       0.56   \n",
       "...                   ...                   ...      ...   ...        ...   \n",
       "1138                 29.0                  40.0  0.99574  3.42       0.75   \n",
       "1139                 28.0                  38.0  0.99651  3.42       0.82   \n",
       "1140                 32.0                  44.0  0.99490  3.45       0.58   \n",
       "1141                 39.0                  51.0  0.99512  3.52       0.76   \n",
       "1142                 32.0                  44.0  0.99547  3.57       0.71   \n",
       "\n",
       "      alcohol  quality  \n",
       "0         9.4        5  \n",
       "1         9.8        5  \n",
       "2         9.8        5  \n",
       "3         9.8        6  \n",
       "4         9.4        5  \n",
       "...       ...      ...  \n",
       "1138     11.0        6  \n",
       "1139      9.5        6  \n",
       "1140     10.5        5  \n",
       "1141     11.2        6  \n",
       "1142     10.2        5  \n",
       "\n",
       "[1143 rows x 12 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "15b3b9e4-063d-4176-a026-a2e87a21f11f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e8661e91-6ab1-46c9-8fcd-046c797c5d31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-Validation Accuracy Scores: [0.90909091 0.85227273 0.94318182 0.89772727 0.82954545 0.85227273\n",
      " 0.86206897 0.88505747 0.89655172 0.85057471 0.83908046 0.89655172\n",
      " 0.87356322 0.86206897 0.82758621 0.88505747 0.83908046 0.85057471\n",
      " 0.93103448 0.97701149]\n",
      "Mean CV Accuracy: 0.8779976489028213\n",
      "Validation Accuracy: 0.5131004366812227\n",
      "\n",
      "Classification Report (Validation):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           3       0.00      0.00      0.00         2\n",
      "           4       0.09      0.18      0.12        11\n",
      "           5       0.63      0.62      0.62       192\n",
      "           6       0.52      0.48      0.50       194\n",
      "           7       0.40      0.38      0.39        52\n",
      "           8       0.00      0.00      0.00         7\n",
      "\n",
      "    accuracy                           0.51       458\n",
      "   macro avg       0.27      0.28      0.27       458\n",
      "weighted avg       0.53      0.51      0.52       458\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Load a sample dataset (Iris dataset as an example)\n",
    "\n",
    "x=df.drop('quality',axis=1)\n",
    "y=df['quality']\n",
    "\n",
    "# Split the data into training and validation sets (validation size = 20%)\n",
    "x_train, x_val, y_train, y_val = train_test_split(x, y, test_size=0.4)\n",
    "\n",
    "\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "ros = RandomOverSampler(random_state=42)\n",
    "x_trainResampled, y_trainResampled = ros.fit_resample(x_train, y_train)\n",
    "scaler = StandardScaler().fit(x_trainResampled)\n",
    "XtrainResampled = scaler.transform(x_trainResampled)\n",
    "\n",
    "# Initialize the SVM classifier with specified parameters\n",
    "cart_model = DecisionTreeClassifier(\n",
    "    criterion='entropy',\n",
    "    max_depth=None,\n",
    "    min_samples_leaf=1,\n",
    "    min_samples_split=2,\n",
    "    random_state=42  # Ensure reproducibility\n",
    ")\n",
    "\n",
    "# Set up 10-fold cross-validation\n",
    "kfold = StratifiedKFold(n_splits=20)\n",
    "\n",
    "# Perform cross-validation on the training data\n",
    "cv_scores = cross_val_score(cart_model, x_trainResampled, y_trainResampled, cv=kfold, scoring='accuracy')\n",
    "\n",
    "# Train the SVM model on the full training set\n",
    "cart_model.fit(x_trainResampled, y_trainResampled)\n",
    "\n",
    "# Validate the model on the validation set\n",
    "y_val_pred = cart_model.predict(x_val)\n",
    "\n",
    "# Evaluate performance\n",
    "print(\"Cross-Validation Accuracy Scores:\", cv_scores)\n",
    "print(\"Mean CV Accuracy:\", cv_scores.mean())\n",
    "print(\"Validation Accuracy:\", accuracy_score(y_val, y_val_pred))\n",
    "print(\"\\nClassification Report (Validation):\\n\", classification_report(y_val, y_val_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "74caa2a8-2448-4c44-b673-1c2c30ff0fa9",
   "metadata": {},
   "outputs": [],
   "source": [
    " from sklearn.ensemble import AdaBoostClassifier\n",
    " from sklearn.ensemble import GradientBoostingClassifier\n",
    " from sklearn.ensemble import RandomForestClassifier\n",
    " from sklearn.ensemble import ExtraTreesClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "920d8f83-fcb3-4452-bfdf-ad39c303bcc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ScaledAB: 0.406654 (0.042663)\n",
      "ScaledGBM: 0.879731 (0.019267)\n",
      "ScaledRF: 0.886611 (0.020677)\n",
      "ScaledDTC: 0.863704 (0.022809)\n",
      "ScaledETC: 0.904916 (0.018883)\n"
     ]
    }
   ],
   "source": [
    "# Standardize the dataset\n",
    "from sklearn.pipeline import Pipeline\n",
    "pipelines = []\n",
    "pipelines.append(('ScaledAB', Pipeline([('Scaler', StandardScaler()),('AB', AdaBoostClassifier())])))\n",
    "pipelines.append(('ScaledGBM', Pipeline([('Scaler', StandardScaler()),('GBM', GradientBoostingClassifier())])))\n",
    "pipelines.append(('ScaledRF', Pipeline([('Scaler', StandardScaler()),('RF', RandomForestClassifier())])))\n",
    "pipelines.append(('ScaledDTC', Pipeline([('Scaler', StandardScaler()),('DTC',DecisionTreeClassifier())])))\n",
    "pipelines.append(('ScaledETC', Pipeline([('Scaler', StandardScaler()),('ETC', ExtraTreesClassifier())])))\n",
    "results = []\n",
    "names = []\n",
    "for name, model in pipelines:\n",
    "    kfold = KFold(n_splits=10 )\n",
    "    cv_results = cross_val_score(model,x_trainResampled, y_trainResampled,  cv=10, scoring='accuracy')\n",
    "    results.append(cv_results)\n",
    "    names.append(name)\n",
    "    msg = \"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std())\n",
    "    print(msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a74a3133-344a-41f3-a67c-4d2daa250cd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.908275 using {'n_estimators': 400}\n",
      "0.902018 (0.124722) with: {'n_estimators': 50}\n",
      "0.903148 (0.121844) with: {'n_estimators': 100}\n",
      "0.904846 (0.121119) with: {'n_estimators': 150}\n",
      "0.905401 (0.118974) with: {'n_estimators': 200}\n",
      "0.906550 (0.118843) with: {'n_estimators': 250}\n",
      "0.908275 (0.115534) with: {'n_estimators': 300}\n",
      "0.907132 (0.117419) with: {'n_estimators': 350}\n",
      "0.908275 (0.114458) with: {'n_estimators': 400}\n"
     ]
    }
   ],
   "source": [
    " # Tune scaled RF\n",
    " from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score, GridSearchCV\n",
    " scaler = StandardScaler().fit(x_trainResampled)\n",
    " rescaledX = scaler.transform(x_trainResampled)\n",
    " param_grid = dict(n_estimators=np.array([50,100,150,200,250,300,350,400]))\n",
    " model = ExtraTreesClassifier()\n",
    " kfold = KFold(n_splits=20)\n",
    " grid = GridSearchCV(estimator=model, param_grid=param_grid, scoring='accuracy', cv=kfold)\n",
    " grid_result = grid.fit(rescaledX, y_trainResampled)\n",
    " print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    " means = grid_result.cv_results_['mean_test_score']\n",
    " stds = grid_result.cv_results_['std_test_score']\n",
    " params = grid_result.cv_results_['params']\n",
    " for mean, stdev, param in zip(means, stds, params):\n",
    "     print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9040b64e-8643-432a-9180-53334fa853f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resampled class distribution: Counter({6: 289, 8: 289, 5: 289, 7: 289, 4: 289, 3: 289})\n",
      "Fitting 10 folds for each of 108 candidates, totalling 1080 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.17.3 and <1.25.0 is required for this version of SciPy (detected version 1.26.4\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n",
      "/usr/lib/python3/dist-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.17.3 and <1.25.0 is required for this version of SciPy (detected version 1.26.4\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n",
      "/usr/lib/python3/dist-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.17.3 and <1.25.0 is required for this version of SciPy (detected version 1.26.4\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n",
      "/usr/lib/python3/dist-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.17.3 and <1.25.0 is required for this version of SciPy (detected version 1.26.4\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n",
      "/usr/lib/python3/dist-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.17.3 and <1.25.0 is required for this version of SciPy (detected version 1.26.4\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n",
      "/usr/lib/python3/dist-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.17.3 and <1.25.0 is required for this version of SciPy (detected version 1.26.4\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n",
      "/usr/lib/python3/dist-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.17.3 and <1.25.0 is required for this version of SciPy (detected version 1.26.4\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n",
      "/usr/lib/python3/dist-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.17.3 and <1.25.0 is required for this version of SciPy (detected version 1.26.4\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 100}\n",
      "Best Cross-Validation Accuracy: 0.8955816889243241\n",
      "Validation Accuracy: 0.6943231441048034\n",
      "\n",
      "Classification Report (Validation):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           3       0.00      0.00      0.00         2\n",
      "           4       0.00      0.00      0.00        13\n",
      "           5       0.73      0.79      0.76       194\n",
      "           6       0.65      0.72      0.69       185\n",
      "           7       0.71      0.53      0.61        57\n",
      "           8       1.00      0.14      0.25         7\n",
      "\n",
      "    accuracy                           0.69       458\n",
      "   macro avg       0.52      0.36      0.38       458\n",
      "weighted avg       0.68      0.69      0.68       458\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from collections import Counter\n",
    "\n",
    "# Load your dataset (replace this with your dataset)\n",
    "# Assume 'df' contains the data and 'quality' is the target variable\n",
    "# Example: df = pd.read_csv(\"your_dataset.csv\")\n",
    "x = df.drop('quality', axis=1)\n",
    "y = df['quality']\n",
    "\n",
    "# Split the data into training and validation sets (40% validation set)\n",
    "x_train, x_val, y_train, y_val = train_test_split(x, y, test_size=0.4, stratify=y, random_state=42)\n",
    "\n",
    "# Scale the features\n",
    "scaler = StandardScaler()\n",
    "x_train = scaler.fit_transform(x_train)\n",
    "x_val = scaler.transform(x_val)\n",
    "\n",
    "# Address class imbalance with RandomOverSampler\n",
    "ros = RandomOverSampler(random_state=42)\n",
    "x_train_resampled, y_train_resampled = ros.fit_resample(x_train, y_train)\n",
    "print(\"Resampled class distribution:\", Counter(y_train_resampled))\n",
    "\n",
    "# Initialize the ExtraTreesClassifier\n",
    "model = ExtraTreesClassifier(random_state=42)\n",
    "\n",
    "# Define the parameter grid for GridSearchCV\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 500],  # Number of trees\n",
    "    'max_depth': [None, 10, 20, 30],  # Maximum depth of the tree\n",
    "    'min_samples_split': [2, 5, 10],  # Minimum samples required to split an internal node\n",
    "    'min_samples_leaf': [1, 2, 4],    # Minimum samples required to be a leaf node\n",
    "}\n",
    "\n",
    "# Set up cross-validation\n",
    "kfold = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "# Perform GridSearchCV for parameter tuning\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=model, \n",
    "    param_grid=param_grid, \n",
    "    cv=kfold, \n",
    "    scoring='accuracy', \n",
    "    n_jobs=-1, \n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Fit the model to the resampled training data\n",
    "grid_search.fit(x_train_resampled, y_train_resampled)\n",
    "\n",
    "# Print the best parameters and the corresponding score\n",
    "print(\"Best Parameters:\", grid_search.best_params_)\n",
    "print(\"Best Cross-Validation Accuracy:\", grid_search.best_score_)\n",
    "\n",
    "# Use the best model from GridSearchCV\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# Train the model on the full resampled training set\n",
    "best_model.fit(x_train_resampled, y_train_resampled)\n",
    "\n",
    "# Validate the model on the validation set\n",
    "y_val_pred = best_model.predict(x_val)\n",
    "\n",
    "# Evaluate performance on the validation set\n",
    "print(\"Validation Accuracy:\", accuracy_score(y_val, y_val_pred))\n",
    "print(\"\\nClassification Report (Validation):\\n\", classification_report(y_val, y_val_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0c6f5b7f-ea47-4851-9b76-4abcf3518e66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-Validation Accuracy Scores: [0.88505747 0.88505747 0.81395349 0.90697674 0.90697674 0.89534884\n",
      " 0.89534884 0.90697674 0.90697674 0.91860465 0.89534884 0.89534884\n",
      " 0.91860465 0.87209302 0.88372093 0.93023256 0.84883721 0.91860465\n",
      " 0.89534884 0.90697674]\n",
      "Mean CV Accuracy: 0.8943197006148088\n",
      "Validation Accuracy: 0.6746724890829694\n",
      "\n",
      "Classification Report (Validation):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           3       0.00      0.00      0.00         1\n",
      "           4       0.00      0.00      0.00        13\n",
      "           5       0.75      0.77      0.76       196\n",
      "           6       0.60      0.76      0.67       176\n",
      "           7       0.73      0.38      0.50        63\n",
      "           8       1.00      0.11      0.20         9\n",
      "\n",
      "    accuracy                           0.67       458\n",
      "   macro avg       0.51      0.34      0.35       458\n",
      "weighted avg       0.67      0.67      0.65       458\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Load a sample dataset (Iris dataset as an example)\n",
    "scaler = StandardScaler().fit(XtrainResampled)\n",
    "XtrainResampled = scaler.transform(XtrainResampled)\n",
    "x=df.drop('quality',axis=1)\n",
    "y=df['quality']\n",
    "\n",
    "# Split the data into training and validation sets (validation size = 20%)\n",
    "x_train, x_val, y_train, y_val = train_test_split(x, y, test_size=0.4)\n",
    "\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "ros = RandomOverSampler(random_state=42)\n",
    "x_trainResampled, y_trainResampled = ros.fit_resample(x_train, y_train)\n",
    "\n",
    "# Initialize the SVM classifier with specified parameters\n",
    "model1 = ExtraTreesClassifier(max_depth=None, \n",
    "    min_samples_leaf=1, \n",
    "    min_samples_split=5, \n",
    "    n_estimators=200, \n",
    "    random_state=42)\n",
    "\n",
    "# Set up 10-fold cross-validation\n",
    "kfold = StratifiedKFold(n_splits=20)\n",
    "\n",
    "# Perform cross-validation on the training data\n",
    "cv_scores = cross_val_score(model1, x_trainResampled, y_trainResampled, cv=kfold, scoring='accuracy')\n",
    "\n",
    "# Train the SVM model on the full training set\n",
    "model1.fit(x_trainResampled, y_trainResampled)\n",
    "\n",
    "# Validate the model on the validation set\n",
    "y_val_pred = model1.predict(x_val)\n",
    "\n",
    "# Evaluate performance\n",
    "print(\"Cross-Validation Accuracy Scores:\", cv_scores)\n",
    "print(\"Mean CV Accuracy:\", cv_scores.mean())\n",
    "print(\"Validation Accuracy:\", accuracy_score(y_val, y_val_pred))\n",
    "print(\"\\nClassification Report (Validation):\\n\", classification_report(y_val, y_val_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "19d93686-38f7-47c8-b940-b25c3362600e",
   "metadata": {},
   "outputs": [],
   "source": [
    " # Load libraries\n",
    " import numpy\n",
    " from numpy import arange\n",
    " from matplotlib import pyplot\n",
    " from pandas import read_csv\n",
    " from pandas import set_option\n",
    " from sklearn.preprocessing import StandardScaler\n",
    " from sklearn.model_selection import train_test_split\n",
    " from sklearn.model_selection import KFold\n",
    " from sklearn.model_selection import cross_val_score\n",
    " from sklearn.model_selection import GridSearchCV\n",
    " from sklearn.linear_model import LinearRegression\n",
    " from sklearn.linear_model import Lasso\n",
    " from sklearn.linear_model import ElasticNet\n",
    " from sklearn.tree import DecisionTreeRegressor\n",
    " from sklearn.neighbors import KNeighborsRegressor\n",
    " from sklearn.svm import SVR\n",
    " from sklearn.pipeline import Pipeline\n",
    " from sklearn.ensemble import RandomForestRegressor\n",
    " from sklearn.ensemble import GradientBoostingRegressor\n",
    " from sklearn.ensemble import ExtraTreesRegressor\n",
    " from sklearn.ensemble import AdaBoostRegressor\n",
    " from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6ee874ae-6fcb-4203-b201-1fa681f7168a",
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_size = 0.20\n",
    "X_train, X_validation, Y_train, Y_validation = train_test_split(x, y,test_size=validation_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "62300ce3-cc1a-4c0a-8621-d1edb401b869",
   "metadata": {},
   "outputs": [],
   "source": [
    "scoring = 'neg_mean_squared_error'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b1df6224-b495-46e7-8ba8-f6512ac6af10",
   "metadata": {},
   "outputs": [],
   "source": [
    " # Spot-Check Algorithms\n",
    " models = []\n",
    " models.append(('LR', LinearRegression()))\n",
    " models.append(('LASSO', Lasso()))\n",
    " models.append(('EN', ElasticNet()))\n",
    " models.append(('KNN', KNeighborsRegressor()))\n",
    " models.append(('CART', DecisionTreeRegressor()))\n",
    " models.append(('SVR', SVR()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d5768cb7-cd77-4df2-96b7-5f393ca07c64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR -1.037616699324557\n",
      "LASSO -3.0356814084698707\n",
      "EN -2.4671292337333175\n",
      "KNN -0.2697172817100222\n",
      "CART -0.21666666666666667\n",
      "SVR -1.9136777290083284\n"
     ]
    }
   ],
   "source": [
    " # evaluate each model in turn\n",
    " results = []\n",
    " names = []\n",
    " for name, model in models:\n",
    "     kfold = KFold(n_splits=30)\n",
    "     cv_results = cross_val_score(model,x_trainResampled, y_trainResampled ,cv=kfold, scoring=scoring)\n",
    "     results.append(cv_results)\n",
    "     names.append(name)\n",
    "     print(name, cv_results.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "57629bad-126c-443d-ac45-dbe9e5720ef9",
   "metadata": {},
   "outputs": [],
   "source": [
    " import numpy\n",
    " from numpy import arange\n",
    " from matplotlib import pyplot\n",
    " from pandas import read_csv\n",
    " from pandas import set_option\n",
    " from pandas.plotting import scatter_matrix\n",
    " from sklearn.preprocessing import StandardScaler\n",
    " from sklearn.model_selection import train_test_split\n",
    " from sklearn.model_selection import KFold\n",
    " from sklearn.model_selection import cross_val_score\n",
    " from sklearn.model_selection import GridSearchCV\n",
    " from sklearn.linear_model import LinearRegression\n",
    " from sklearn.linear_model import Lasso\n",
    " from sklearn.linear_model import ElasticNet\n",
    " from sklearn.tree import DecisionTreeRegressor\n",
    " from sklearn.neighbors import KNeighborsRegressor\n",
    " from sklearn.svm import SVR\n",
    " from sklearn.pipeline import Pipeline\n",
    " from sklearn.ensemble import RandomForestRegressor\n",
    " from sklearn.ensemble import GradientBoostingRegressor\n",
    " from sklearn.ensemble import ExtraTreesRegressor\n",
    " from sklearn.ensemble import AdaBoostRegressor\n",
    " from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "200d5915-73f4-4429-8dbc-9c03c4586142",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ScaledLR: -1.079000 (0.286710)\n",
      "ScaledLASSO: -2.964380 (2.434664)\n",
      "ScaledEN: -2.118189 (1.637055)\n",
      "ScaledKNN: -0.268578 (0.302174)\n",
      "ScaledCART: -0.203448 (0.254612)\n",
      "ScaledSVR: -0.399993 (0.265182)\n"
     ]
    }
   ],
   "source": [
    " pipelines = []\n",
    " pipelines.append(('ScaledLR', Pipeline([('Scaler', StandardScaler()),('LR',LinearRegression())])))\n",
    " pipelines.append(('ScaledLASSO', Pipeline([('Scaler', StandardScaler()),('LASSO',Lasso())])))\n",
    " pipelines.append(('ScaledEN', Pipeline([('Scaler', StandardScaler()),('EN',ElasticNet())])))\n",
    " pipelines.append(('ScaledKNN', Pipeline([('Scaler', StandardScaler()),('KNN',KNeighborsRegressor())])))\n",
    " pipelines.append(('ScaledCART', Pipeline([('Scaler', StandardScaler()),('CART',DecisionTreeRegressor())])))\n",
    " pipelines.append(('ScaledSVR', Pipeline([('Scaler', StandardScaler()),('SVR', SVR())])))\n",
    " results = []\n",
    " names = []\n",
    " for name, model in pipelines:\n",
    "     kfold = KFold(n_splits=20)\n",
    "     cv_results = cross_val_score(model,x_trainResampled, y_trainResampled , cv=kfold, scoring=scoring)\n",
    "     results.append(cv_results)\n",
    "     names.append(name)\n",
    "     msg = \"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std())\n",
    "     print(msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "9654be50-3791-4e79-82b3-77cd651ba142",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ScaledAB: -0.419382 (0.102744)\n",
      "ScaledGBM: -0.400789 (0.108343)\n",
      "ScaledRF: -0.356122 (0.102707)\n",
      "ScaledET: -0.344632 (0.105179)\n"
     ]
    }
   ],
   "source": [
    " ensembles = []\n",
    " ensembles.append(('ScaledAB', Pipeline([('Scaler', StandardScaler()),('AB',AdaBoostRegressor())])))\n",
    " ensembles.append(('ScaledGBM', Pipeline([('Scaler', StandardScaler()),('GBM',GradientBoostingRegressor())])))\n",
    " ensembles.append(('ScaledRF', Pipeline([('Scaler', StandardScaler()),('RF',RandomForestRegressor())])))\n",
    " ensembles.append(('ScaledET', Pipeline([('Scaler', StandardScaler()),('ET',ExtraTreesRegressor())])))\n",
    " results = []\n",
    " names = []\n",
    " for name, model in ensembles:\n",
    "     kfold = KFold(n_splits=20)\n",
    "     cv_results = cross_val_score(model,X_train, Y_train, cv=kfold, scoring=scoring)\n",
    "     results.append(cv_results)\n",
    "     names.append(name)\n",
    "     msg = \"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std())\n",
    "     print(msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "37d7ee66-8c72-4375-97a0-a6b7ed8140a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 108 candidates, totalling 1080 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.17.3 and <1.25.0 is required for this version of SciPy (detected version 1.26.4\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n",
      "/usr/lib/python3/dist-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.17.3 and <1.25.0 is required for this version of SciPy (detected version 1.26.4\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n",
      "/usr/lib/python3/dist-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.17.3 and <1.25.0 is required for this version of SciPy (detected version 1.26.4\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n",
      "/usr/lib/python3/dist-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.17.3 and <1.25.0 is required for this version of SciPy (detected version 1.26.4\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n",
      "/usr/lib/python3/dist-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.17.3 and <1.25.0 is required for this version of SciPy (detected version 1.26.4\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n",
      "/usr/lib/python3/dist-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.17.3 and <1.25.0 is required for this version of SciPy (detected version 1.26.4\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n",
      "/usr/lib/python3/dist-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.17.3 and <1.25.0 is required for this version of SciPy (detected version 1.26.4\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n",
      "/usr/lib/python3/dist-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.17.3 and <1.25.0 is required for this version of SciPy (detected version 1.26.4\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'max_depth': 20, 'max_features': 'sqrt', 'min_samples_leaf': 2, 'min_samples_split': 2}\n",
      "Best Cross-Validation MSE: 0.16681185990181074\n",
      "Validation MSE: 0.6328166929071483\n",
      "Validation MAE: 0.5129340819297152\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, KFold, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from collections import Counter\n",
    "\n",
    "# Load your dataset (replace this with your dataset)\n",
    "# Assume 'df' contains the data and 'target' is the regression target variable\n",
    "# Example: df = pd.read_csv(\"your_dataset.csv\")\n",
    "x = df.drop('quality', axis=1)  # Replace 'quality' with your target variable name\n",
    "y = df['quality']\n",
    "\n",
    "# Split the data into training and validation sets (40% validation set)\n",
    "x_train, x_val, y_train, y_val = train_test_split(x, y, test_size=0.4, random_state=42)\n",
    "\n",
    "# Scale the features\n",
    "\n",
    "ros = RandomOverSampler(random_state=42)\n",
    "x_train_resampled, y_train_resampled = ros.fit_resample(x_train, y_train)\n",
    "scaler = StandardScaler()\n",
    "x_train = scaler.fit_transform(x_train_resampled)\n",
    "x_val = scaler.transform(x_val)\n",
    "\n",
    "# Initialize the DecisionTreeRegressor (CART)\n",
    "model = DecisionTreeRegressor(random_state=42)\n",
    "\n",
    "# Define the parameter grid for GridSearchCV\n",
    "param_grid = {\n",
    "    'max_depth': [None, 10, 20, 30],        # Maximum depth of the tree\n",
    "    'min_samples_split': [2, 5, 10],       # Minimum samples required to split an internal node\n",
    "    'min_samples_leaf': [1, 2, 4],         # Minimum samples required to be a leaf node\n",
    "    'max_features': [None, 'sqrt', 'log2'] # Number of features to consider for the best split\n",
    "}\n",
    "\n",
    "# Set up cross-validation\n",
    "kfold = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "# Perform GridSearchCV for parameter tuning\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=model,\n",
    "    param_grid=param_grid,\n",
    "    cv=kfold,\n",
    "    scoring='neg_mean_squared_error',  # Regression scoring\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Fit the model to the training data\n",
    "grid_search.fit(x_train, y_train_resampled)\n",
    "\n",
    "# Print the best parameters and the corresponding score\n",
    "print(\"Best Parameters:\", grid_search.best_params_)\n",
    "print(\"Best Cross-Validation MSE:\", -grid_search.best_score_)\n",
    "\n",
    "# Use the best model from GridSearchCV\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# Train the model on the full training set\n",
    "best_model.fit(x_train, y_train_resampled)\n",
    "\n",
    "# Validate the model on the validation set\n",
    "y_val_pred = best_model.predict(x_val)\n",
    "\n",
    "# Evaluate performance on the validation set\n",
    "mse = mean_squared_error(y_val, y_val_pred)\n",
    "mae = mean_absolute_error(y_val, y_val_pred)\n",
    "print(\"Validation MSE:\", mse)\n",
    "print(\"Validation MAE:\", mae)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e6c5c1eb-71ec-47df-bd74-daa555d2d0e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation MSE: 0.6376152353226588\n",
      "Validation MAE: 0.5425764192139738\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "# Load your dataset (replace this with your dataset)\n",
    "# Assume 'df' contains the data and 'target' is the regression target variable\n",
    "x = df.drop('quality', axis=1)  # Replace 'quality' with your target variable name\n",
    "y = df['quality']\n",
    "\n",
    "# Split the data into training and validation sets (40% validation set)\n",
    "x_train, x_val, y_train, y_val = train_test_split(x, y, test_size=0.4, random_state=42)\n",
    "\n",
    "# Scale the features\n",
    "scaler = StandardScaler()\n",
    "x_train = scaler.fit_transform(x_train)\n",
    "x_val = scaler.transform(x_val)\n",
    "\n",
    "# Initialize the DecisionTreeRegressor with best parameters\n",
    "best_model = DecisionTreeRegressor(\n",
    "    max_depth=20,\n",
    "    max_features='sqrt',\n",
    "    min_samples_leaf=2,\n",
    "    min_samples_split=2,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Train the model on the training set\n",
    "best_model.fit(x_train, y_train)\n",
    "\n",
    "# Validate the model on the validation set\n",
    "y_val_pred = best_model.predict(x_val)\n",
    "\n",
    "# Evaluate performance on the validation set\n",
    "mse = mean_squared_error(y_val, y_val_pred)\n",
    "mae = mean_absolute_error(y_val, y_val_pred)\n",
    "print(\"Validation MSE:\", mse)\n",
    "print(\"Validation MAE:\", mae)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99e76266-7709-4cd4-a2ba-dfafea0bf0e7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
